{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model\n",
    "\n",
    "The first step is to load the data extracted from our transactional data (warehouse)\n",
    "The queries used are saved in this repo for documentation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "cart_items = pd.read_csv('data_git/cart_items.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit about how the data is structured at Metaloop. We essentially have these sources of trasactional material data:\n",
    "\n",
    " - Cart items\n",
    "    - These are the materials that compose a transaction (stored in the orders object). Each order is associated with two accounts, a seller and a buyer. Therefore, the lowest granularity data here will be cart item level data with data from the orders joined\n",
    " - Opportunity materials\n",
    "    - These play a similar role as cart items, but on the opportunity level (prior to an order being put forward)\n",
    "   \n",
    " - Conditions (Contract materials)\n",
    "\n",
    "For the purpose of this baseline model, we will use only cart items data, which is our most comprehensive database.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple bag of words model\n",
    "\n",
    "With a simple bag of words model, we try to extract features from the alias, material and formula fields. Our target variable is the variable product_id, which is a class corresponding to the underlying product related to the material. This is encoded by the class in the `fk_material` column.\n",
    "\n",
    "### The training of an NLP model\n",
    "\n",
    "1. Preprocessing the text\n",
    "2. Vectozing the text\n",
    "3. Choose appropriate ML model to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change ds_material_alias to string\n",
    "cart_items['ds_material_alias'] = cart_items['ds_material_alias'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define functions to extract metadata about the text of the alias names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds_sale_price_formula</th>\n",
       "      <th>ds_purchase_price_formula</th>\n",
       "      <th>ds_material_alias</th>\n",
       "      <th>vl_quantity_sell</th>\n",
       "      <th>vl_unit_price_sell</th>\n",
       "      <th>cd_alias_language</th>\n",
       "      <th>cd_product_id</th>\n",
       "      <th>lower(ds_category_en)</th>\n",
       "      <th>lower(ds_record_type_name)</th>\n",
       "      <th>flg_has_perc</th>\n",
       "      <th>n_words_alias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kupfer Raff Granulat</td>\n",
       "      <td>2163.0</td>\n",
       "      <td>6.10000</td>\n",
       "      <td>de</td>\n",
       "      <td>60001.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>wholesale - europe domestic</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kupfer-Nickel, blank</td>\n",
       "      <td>17500.0</td>\n",
       "      <td>13.18583</td>\n",
       "      <td>de</td>\n",
       "      <td>600041.0</td>\n",
       "      <td>copper</td>\n",
       "      <td>wholesale - europe domestic</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edelstahl, V2A, Nirosta, Niro</td>\n",
       "      <td>14560.0</td>\n",
       "      <td>2.01000</td>\n",
       "      <td>de</td>\n",
       "      <td>18037.0</td>\n",
       "      <td>stainless steel</td>\n",
       "      <td>wholesale - europe domestic</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edelstahl, V2A, Nirosta, Niro</td>\n",
       "      <td>1484.0</td>\n",
       "      <td>2.06000</td>\n",
       "      <td>de</td>\n",
       "      <td>18037.0</td>\n",
       "      <td>stainless steel</td>\n",
       "      <td>wholesale - europe domestic</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Edelstahl, V4A Schrott</td>\n",
       "      <td>5980.0</td>\n",
       "      <td>2.80000</td>\n",
       "      <td>de</td>\n",
       "      <td>18039.0</td>\n",
       "      <td>stainless steel</td>\n",
       "      <td>wholesale - europe domestic</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ds_sale_price_formula ds_purchase_price_formula  \\\n",
       "0                   NaN                       NaN   \n",
       "1                   NaN                       NaN   \n",
       "2                   NaN                       NaN   \n",
       "3                   NaN                       NaN   \n",
       "4                   NaN                       NaN   \n",
       "\n",
       "               ds_material_alias  vl_quantity_sell  vl_unit_price_sell  \\\n",
       "0           Kupfer Raff Granulat            2163.0             6.10000   \n",
       "1           Kupfer-Nickel, blank           17500.0            13.18583   \n",
       "2  Edelstahl, V2A, Nirosta, Niro           14560.0             2.01000   \n",
       "3  Edelstahl, V2A, Nirosta, Niro            1484.0             2.06000   \n",
       "4         Edelstahl, V4A Schrott            5980.0             2.80000   \n",
       "\n",
       "  cd_alias_language  cd_product_id lower(ds_category_en)  \\\n",
       "0                de        60001.0                copper   \n",
       "1                de       600041.0                copper   \n",
       "2                de        18037.0       stainless steel   \n",
       "3                de        18037.0       stainless steel   \n",
       "4                de        18039.0       stainless steel   \n",
       "\n",
       "    lower(ds_record_type_name)  flg_has_perc  n_words_alias  \n",
       "0  wholesale - europe domestic         False              3  \n",
       "1  wholesale - europe domestic         False              2  \n",
       "2  wholesale - europe domestic         False              4  \n",
       "3  wholesale - europe domestic         False              4  \n",
       "4  wholesale - europe domestic         False              3  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define function to count words\n",
    "def count_words(string):\n",
    "    return len(string.split())\n",
    "\n",
    "# Define function to get the average word length\n",
    "def avg_word_length(string):\n",
    "    words = string.split()\n",
    "    return sum(len(word) for word in words) / len(words)\n",
    "\n",
    "# Check if the description has the percentage symbol\n",
    "cart_items['flg_has_perc'] = cart_items['ds_material_alias'].apply(lambda x: len([c for c in x if c == '%'])>0)\n",
    "\n",
    "# Create number of words for the two columns available\n",
    "cart_items['n_words_alias'] = cart_items['ds_material_alias'].apply(count_words)\n",
    "\n",
    "# Inspect results\n",
    "cart_items.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the data to lower case\n",
    "cart_items['ds_material_alias'] = cart_items['ds_material_alias'].str.lower()\n",
    "\n",
    "# Removing the leading and trailing whitespaces\n",
    "cart_items['ds_material_alias'] = cart_items['ds_material_alias'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formula parsing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    avg_1: 0.9903524443722592\n",
      "    avg_2: 0.9935520545720319\n"
     ]
    }
   ],
   "source": [
    "avg_1 = np.mean(cart_items['ds_sale_price_formula'].isna())\n",
    "\n",
    "avg_2 = np.mean(cart_items['ds_purchase_price_formula'] == 'nan')\n",
    "\n",
    "print(\n",
    "    \"\"\"\n",
    "    avg_1: {}\n",
    "    avg_2: {}\"\"\".format(avg_1, avg_2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "module_path = 'models'\n",
    "sys.path.append(module_path)\n",
    "\n",
    "# Import the functions from the python file\n",
    "import formula_parsing_function as fpf\n",
    "\n",
    "# Apply the functions to the column\n",
    "\n",
    "# Change formula type to\n",
    "cart_items['ds_sale_price_formula'] = cart_items['ds_sale_price_formula'].astype(str)\n",
    "\n",
    "# Detect currency\n",
    "cart_items['currency'] = cart_items['ds_sale_price_formula'].apply(fpf.detect_currency)\n",
    "\n",
    "# Get operator\n",
    "cart_items['operator'] = cart_items['ds_sale_price_formula'].apply(fpf.detect_operator)\n",
    "\n",
    "# Get index\n",
    "cart_items['index'] = cart_items['ds_sale_price_formula'].apply(fpf.detect_index)\n",
    "\n",
    "# Get constant\n",
    "cart_items['constant'] = cart_items['ds_sale_price_formula'].apply(fpf.detect_constant)\n",
    "\n",
    "# Convert to float\n",
    "cart_items['constant'] = cart_items['constant'].apply(fpf.convert_constant)\n",
    "\n",
    "# Get unit\n",
    "cart_items['unit'] = cart_items['ds_sale_price_formula'].apply(fpf.detect_unit)\n",
    "\n",
    "# Identify if the price is fixed\n",
    "cart_items['fixed_price'] = cart_items['ds_sale_price_formula'].str.contains('fix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of preprocessing\n",
    "----\n",
    "\n",
    "### Vectorization\n",
    "\n",
    "Now that we have done the pre-processing of the text, we can work on vectorizing it. We will apply three simple methods to arrive at the baseline for the feature extraction of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We will start now training the baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input argument must be uniformly strings or numbers. Got ['int', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/imperial_repos/work_based_project/venv/lib/python3.11/site-packages/sklearn/utils/_encode.py:174\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    172\u001b[0m uniques_set, missing_values \u001b[38;5;241m=\u001b[39m _extract_missing(uniques_set)\n\u001b[0;32m--> 174\u001b[0m uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(uniques_set)\n\u001b[1;32m    175\u001b[0m uniques\u001b[38;5;241m.\u001b[39mextend(missing_values\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'int'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m oe \u001b[38;5;241m=\u001b[39m OrdinalEncoder(handle_unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_encoded_value\u001b[39m\u001b[38;5;124m'\u001b[39m, unknown_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Fit and transform the training data\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m X_train[:, categorical_features] \u001b[38;5;241m=\u001b[39m \u001b[43moe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Transform the testing data\u001b[39;00m\n\u001b[1;32m     31\u001b[0m X_test[:, categorical_features] \u001b[38;5;241m=\u001b[39m oe\u001b[38;5;241m.\u001b[39mtransform(X_test[:, categorical_features])\n",
      "File \u001b[0;32m~/Desktop/imperial_repos/work_based_project/venv/lib/python3.11/site-packages/sklearn/utils/_set_output.py:295\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    298\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    299\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    300\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    301\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/imperial_repos/work_based_project/venv/lib/python3.11/site-packages/sklearn/base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1084\u001b[0m             (\n\u001b[1;32m   1085\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) has a `transform`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/Desktop/imperial_repos/work_based_project/venv/lib/python3.11/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/imperial_repos/work_based_project/venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:1495\u001b[0m, in \u001b[0;36mOrdinalEncoder.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1489\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown_value should only be set when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhandle_unknown is \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_encoded_value\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1491\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munknown_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1492\u001b[0m     )\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;66;03m# `_fit` will only raise an error when `self.handle_unknown=\"error\"`\u001b[39;00m\n\u001b[0;32m-> 1495\u001b[0m fit_results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1496\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1498\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1499\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_and_ignore_missing_for_infrequent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1500\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_missing_indices \u001b[38;5;241m=\u001b[39m fit_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmissing_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1503\u001b[0m cardinalities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mlen\u001b[39m(categories) \u001b[38;5;28;01mfor\u001b[39;00m categories \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories_]\n",
      "File \u001b[0;32m~/Desktop/imperial_repos/work_based_project/venv/lib/python3.11/site-packages/sklearn/preprocessing/_encoders.py:98\u001b[0m, in \u001b[0;36m_BaseEncoder._fit\u001b[0;34m(self, X, handle_unknown, force_all_finite, return_counts, return_and_ignore_missing_for_infrequent)\u001b[0m\n\u001b[1;32m     95\u001b[0m Xi \u001b[38;5;241m=\u001b[39m X_list[i]\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcategories \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 98\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compute_counts:\n\u001b[1;32m    100\u001b[0m         cats, counts \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/Desktop/imperial_repos/work_based_project/venv/lib/python3.11/site-packages/sklearn/utils/_encode.py:42\u001b[0m, in \u001b[0;36m_unique\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unique_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# numerical\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _unique_np(\n\u001b[1;32m     47\u001b[0m     values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[1;32m     48\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/imperial_repos/work_based_project/venv/lib/python3.11/site-packages/sklearn/utils/_encode.py:179\u001b[0m, in \u001b[0;36m_unique_python\u001b[0;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mtype\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values))\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoders require their input argument must be uniformly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings or numbers. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[1;32m    183\u001b[0m ret \u001b[38;5;241m=\u001b[39m (uniques,)\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_inverse:\n",
      "\u001b[0;31mTypeError\u001b[0m: Encoders require their input argument must be uniformly strings or numbers. Got ['int', 'str']"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Your original features and categorical feature indices\n",
    "features = [\n",
    "    'vl_quantity_sell', 'vl_unit_price_sell', 'currency', 'operator', 'index',\n",
    "    'constant', 'unit', 'fixed_price'\n",
    "]\n",
    "categorical_features = [2, 3, 4, 6]  # Column indices of categorical features\n",
    "\n",
    "label = ['fk_material']\n",
    "\n",
    "# Declare the features and the label\n",
    "X = cart_items[features].fillna(0).to_numpy()\n",
    "y = cart_items[label].to_numpy()\n",
    "\n",
    "# Split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode the categorical features using OrdinalEncoder\n",
    "oe = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train[:, categorical_features] = oe.fit_transform(X_train[:, categorical_features])\n",
    "\n",
    "# Transform the testing data\n",
    "X_test[:, categorical_features] = oe.transform(X_test[:, categorical_features])\n",
    "\n",
    "# Import the model and instantiate it\n",
    "rf = RandomForestRegressor()\n",
    "\n",
    "# Fit the model\n",
    "rf.fit(X_train, y_train.ravel())  # Flatten y_train since it has the shape (n_samples, 1)\n",
    "\n",
    "# Predict the model\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error: \", mse)\n",
    "\n",
    "# Plot feature importance\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X.shape[1]), np.array(features)[indices], rotation=90)\n",
    "plt.xlim([-1, X.shape[1]])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
